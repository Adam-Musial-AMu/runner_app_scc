# ğŸƒ Half-Marathon Time Predictor

An application for **estimating half-marathon finish time** using data available  
**before race day** (*pre-race inference*).

The project implements a **complete, production-grade ML pipeline**:
- data preparation and validation,
- model training and versioning,
- inference via a Streamlit application,
- structured data extraction from free-form user text (LLM),
- extraction quality monitoring (Langfuse),
- deployment on **Streamlit Community Cloud**,
- independent model versioning via **GitHub Releases**.

---

## ğŸ¯ Project Goal

The goal of this project is to provide a **realistic estimation of half-marathon time**
based on a **minimal set of inputs** that a runner can reasonably know **before the race**.

The project **explicitly avoids data leakage**:
- no use of target-race results,
- no features available only after race start,
- only *pre-race* information is used.

---

## ğŸ§  Trained Models

The system uses **two complementary predictive models**.

### PRE_RACE_5K

Baseline model, used when only minimal input data is available:
- sex,
- age,
- **5 km race time**.

Model characteristics:
- works with minimal input requirements,
- provides stable predictions,
- achieves a mean absolute error (MAE) of approximately **5 minutes**
  on the 2024 test dataset.

---

### PRE_RACE_10K

Extended model, used when the user additionally provides a **10 km time**:
- sex,
- age,
- 5 km time,
- 10 km time.

Advantages:
- better representation of the runnerâ€™s pacing profile,
- lower prediction error compared to the 5K-only model.

The application **automatically selects** this model when the required inputs are present.

---

## ğŸ“Š Validation and Interpretability

- Models are validated using a **temporal split**:
  - training: 2023 data,
  - testing: 2024 data.
- This ensures realistic generalization to future race editions.
- Feature importance analysis confirms that:
  - 5 km and 10 km times are the dominant predictors,
  - age acts as a corrective factor,
  - sex and year have marginal influence.

Model behavior aligns well with domain knowledge.

---

## ğŸ“¦ Model Artifacts

Each model is distributed with a complete set of artifacts:

- **`.pkl` model file** â€“ trained predictive model,
- **`schema.json`** â€“ strict input data contract (types, ranges, allowed values),
- **`metadata.json`** â€“ training context and quality metrics,
- **`latest.json`** â€“ pointer to the currently active model version.

Artifacts are published via **GitHub Releases**, enabling:
- model updates **without redeploying the application**,
- clear and auditable model versioning,
- easy rollback to previous versions,
- future A/B testing scenarios.

The Streamlit app downloads artifacts **dynamically at startup**
and caches them locally (e.g. in `/tmp`).

---

## ğŸ§© Streamlit Application

The Streamlit application:

- accepts a **single free-text input**,
- uses an **LLM (OpenAI)** to extract structured JSON input,
- falls back to **regex-based extraction** when LLM is unavailable,
- applies **anti-hallucination guards**
  (no distance mentioned â†’ no inferred time),
- validates inputs using **Pandera + `schema.json`**,
- automatically selects the appropriate model (5K / 10K),
- presents results including:
  - predicted half-marathon finish time,
  - estimated average pace (min/km),
  - model error information (MAE),
  - a realistic km-by-km pace visualization.

---

## ğŸ” LLM Extraction Monitoring (Langfuse)

LLM-based input extraction is monitored using **Langfuse**:
- trace logging,
- extraction error analysis,
- iterative prompt improvement,
- cost and latency control.

Langfuse integration is **optional** â€” the application runs fully without it.

---

## â˜ï¸ Deployment Architecture

- **Application code**: GitHub repository
- **Model artifacts**: GitHub Releases
- **Inference frontend**: Streamlit Community Cloud
- **Application deployment**: automatic on push to GitHub
- **Model updates**: new GitHub Release (no app redeploy required)

---

## ğŸ› ï¸ Technology Stack

- **Python 3.10**
- **PyCaret 3.3.2**
- **scikit-learn**
- **Streamlit**
- **OpenAI SDK (1.x)** 
- **Langfuse** 
- **Pandera**
- **pandas / numpy / scipy**
- **GitHub Releases**
- **Streamlit Community Cloud**

---

## ğŸš€ Local Development & Execution

To run the application locally:

```bash
pip install -r requirements.txt
streamlit run app.py
```

**Note:**
- Model artifacts are downloaded from GitHub Releases at application startup.
- If OPENAI_API_KEY is not provided, the app automatically falls back to regex-based extraction.

## ğŸ“„ Disclaimer

This project is intended for research and engineering purposes only.
Predictions are approximate estimates and should not replace professional coaching or training advice.

---

# ğŸƒ Half-Marathon Time Predictor

Aplikacja do **szacowania czasu ukoÅ„czenia pÃ³Å‚maratonu** na podstawie danych dostÄ™pnych  
**przed startem biegu** (*pre-race inference*).

Projekt obejmuje **peÅ‚ny, produkcyjny pipeline ML**:
- przygotowanie i walidacjÄ™ danych,
- trenowanie i wersjonowanie modeli,
- inferencjÄ™ w aplikacji Streamlit,
- ekstrakcjÄ™ danych wejÅ›ciowych z tekstu uÅ¼ytkownika (LLM),
- monitoring jakoÅ›ci ekstrakcji (Langfuse),
- wdroÅ¼enie na **Streamlit Community Cloud**,
- niezaleÅ¼ne wersjonowanie modeli w **GitHub Releases**.

---

## ğŸ¯ Cel projektu

Celem projektu jest **realistyczna estymacja czasu pÃ³Å‚maratonu** w oparciu o **minimalny zestaw informacji**, ktÃ³ry zawodnik moÅ¼e znaÄ‡ **przed startem biegu**.

Projekt **Å›wiadomie unika data leakage**:
- nie uÅ¼ywa danych z biegu docelowego,
- nie korzysta z informacji dostÄ™pnych dopiero po starcie,
- wykorzystuje wyÅ‚Ä…cznie cechy znane *pre-race*.

---

## ğŸ§  Wytrenowane modele

W projekcie zastosowano **dwa komplementarne modele predykcyjne**.

### PRE_RACE_5K

Model bazowy, uÅ¼ywany gdy dostÄ™pne sÄ… tylko podstawowe dane:
- pÅ‚eÄ‡,
- wiek,
- czas uzyskany na dystansie **5 km**.

Cechy modelu:
- dziaÅ‚a przy minimalnych wymaganiach wejÅ›ciowych,
- zapewnia stabilnÄ… predykcjÄ™,
- osiÄ…ga Å›redni bÅ‚Ä…d bezwzglÄ™dny (MAE) â‰ˆ **5 minut**  
  na danych testowych z roku 2024.

---

### PRE_RACE_10K

Model rozszerzony, wykorzystywany gdy uÅ¼ytkownik poda dodatkowo czas na **10 km**:
- pÅ‚eÄ‡,
- wiek,
- czas na 5 km,
- czas na 10 km.

Zalety:
- lepsze odwzorowanie tempa zawodnika,
- ok 2 razy niÅ¼szy bÅ‚Ä…d predykcji wzglÄ™dem wariantu 5 km.

Aplikacja **automatycznie wybiera** ten model, jeÅ›li dane wejÅ›ciowe sÄ… dostÄ™pne.

---

## ğŸ“Š Walidacja i interpretowalnoÅ›Ä‡

- Modele walidowane sÄ… **czasowo**:
  - trening: dane z 2023 roku,
  - test: dane z 2024 roku.
- Zapewnia to realistycznÄ… ocenÄ™ generalizacji na przyszÅ‚e edycje biegu.
- Analiza istotnoÅ›ci cech potwierdza, Å¼e:
  - kluczowÄ… rolÄ™ odgrywajÄ… czasy na 5 km i 10 km,
  - wiek dziaÅ‚a jako korekta,
  - pÅ‚eÄ‡ i rok majÄ… wpÅ‚yw marginalny.

Zachowanie modeli jest zgodne z wiedzÄ… dziedzinowÄ….

---

## ğŸ“¦ Artefakty modeli

KaÅ¼dy model posiada kompletny zestaw artefaktÃ³w:

- **model `.pkl`** â€“ wytrenowany model predykcyjny,
- **`schema.json`** â€“ kontrakt danych wejÅ›ciowych (typy, zakresy, dozwolone wartoÅ›ci),
- **`metadata.json`** â€“ metryki jakoÅ›ci i kontekst treningu,
- **`latest.json`** â€“ wskaÅºnik aktualnej wersji modelu.

Artefakty sÄ… publikowane jako **GitHub Releases**, co umoÅ¼liwia:
- aktualizacjÄ™ modeli **bez redeployu aplikacji**,
- jednoznaczne wersjonowanie modeli,
- prosty rollback do wczeÅ›niejszych wersji,
- audyt zmian w czasie.

Aplikacja Streamlit pobiera artefakty **dynamicznie przy starcie**  
i przechowuje je lokalnie w cache (`/tmp`).

---

## ğŸ§© Aplikacja Streamlit

Aplikacja Streamlit:

- przyjmuje **jedno pole tekstowe** jako wejÅ›cie,
- wykorzystuje **LLM (OpenAI)** do ekstrakcji danych do postaci JSON,
- posiada **regex fallback**, gdy LLM jest niedostÄ™pny,
- stosuje **anti-hallucination guards**  
  (brak wzmianki o dystansie â†’ brak wartoÅ›ci),
- waliduje dane wejÅ›ciowe przy uÅ¼yciu **Pandera + `schema.json`**,
- automatycznie dobiera model (5K / 10K),
- prezentuje wynik wraz z:
  - przewidywanym czasem pÃ³Å‚maratonu,
  - tempem min/km,
  - informacjÄ… o Å›rednim bÅ‚Ä™dzie modelu (MAE),
  - realistycznÄ… wizualizacjÄ… tempa km-po-km.

---

## ğŸ” Monitoring ekstrakcji LLM (Langfuse)

Ekstrakcja danych wejÅ›ciowych przez LLM jest monitorowana przy uÅ¼yciu **Langfuse**:
- logowanie traceâ€™Ã³w,
- analiza bÅ‚Ä™dÃ³w ekstrakcji,
- iteracyjne doskonalenie promptÃ³w,
- kontrola kosztÃ³w i latencji.

Integracja jest **opcjonalna** â€” aplikacja dziaÅ‚a rÃ³wnieÅ¼ bez Langfuse.

---

## â˜ï¸ Architektura wdroÅ¼eniowa

- **Kod aplikacji**: GitHub
- **Modele i artefakty**: GitHub Releases
- **Frontend / inference**: Streamlit Community Cloud
- **Deploy aplikacji**: automatyczny po pushu do repozytorium
- **Aktualizacja modeli**: publikacja nowego Release (bez redeployu aplikacji)

---

## ğŸ› ï¸ Stack technologiczny

- **Python 3.10**
- **PyCaret 3.3.2**
- **scikit-learn**
- **Streamlit**
- **OpenAI SDK (1.x)** 
- **Langfuse** 
- **Pandera**
- **pandas / numpy / scipy**
- **GitHub Releases**
- **Streamlit Community Cloud**

---

## ğŸš€ Uruchomienie lokalne

```bash
pip install -r requirements.txt
streamlit run app.py
```

**Uwaga:**
- Aplikacja pobiera modele z GitHub Releases przy starcie.
- Brak klucza OpenAI powoduje automatyczne przejÅ›cie na ekstrakcjÄ™ regex.

## ğŸ“„ Disclaimer

Projekt ma charakter badawczo-inÅ¼ynierski.
Predykcje majÄ… charakter orientacyjny i nie zastÄ™pujÄ… profesjonalnego planu treningowego.
